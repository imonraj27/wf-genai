{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IQ</th>\n",
       "      <th>Prev_Sem_Result</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Academic_Performance</th>\n",
       "      <th>Internship_Experience</th>\n",
       "      <th>Extra_Curricular_Score</th>\n",
       "      <th>Communication_Skills</th>\n",
       "      <th>Projects_Completed</th>\n",
       "      <th>Placement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.28</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>5.52</td>\n",
       "      <td>5.37</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>5.36</td>\n",
       "      <td>5.83</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.75</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>7.91</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    IQ  Prev_Sem_Result  CGPA  Academic_Performance  Internship_Experience  \\\n",
       "0  107             6.61  6.28                     8                      0   \n",
       "1   97             5.52  5.37                     8                      0   \n",
       "2  109             5.36  5.83                     9                      0   \n",
       "3  122             5.47  5.75                     6                      1   \n",
       "4   96             7.91  7.69                     7                      0   \n",
       "\n",
       "   Extra_Curricular_Score  Communication_Skills  Projects_Completed Placement  \n",
       "0                       8                     8                   4        No  \n",
       "1                       7                     8                   0        No  \n",
       "2                       3                     1                   1        No  \n",
       "3                       1                     6                   1        No  \n",
       "4                       8                    10                   2        No  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"college_placement.csv\")\n",
    "df = df.drop(\"College_ID\", axis=1)\n",
    "df[\"Internship_Experience\"] = df[\"Internship_Experience\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 8) (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"Placement\", axis=1).values\n",
    "y = df[\"Placement\"].values.reshape(-1,1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X.shape, y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.2467\n",
      "Epoch 2/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.1701\n",
      "Epoch 3/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1281\n",
      "Epoch 4/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9621 - loss: 0.1019\n",
      "Epoch 5/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0829\n",
      "Epoch 6/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.0716\n",
      "Epoch 7/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0629\n",
      "Epoch 8/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9777 - loss: 0.0586\n",
      "Epoch 9/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0483\n",
      "Epoch 10/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0449\n",
      "Epoch 11/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0412\n",
      "Epoch 12/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0370\n",
      "Epoch 13/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0339\n",
      "Epoch 14/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0308\n",
      "Epoch 15/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0281\n",
      "Epoch 16/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0260\n",
      "Epoch 17/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0239\n",
      "Epoch 18/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0202\n",
      "Epoch 19/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0226\n",
      "Epoch 20/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0190\n",
      "Epoch 21/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0178\n",
      "Epoch 22/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0174\n",
      "Epoch 23/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0178\n",
      "Epoch 24/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0161\n",
      "Epoch 25/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0144\n",
      "Epoch 26/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0146\n",
      "Epoch 27/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0134\n",
      "Epoch 28/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0131\n",
      "Epoch 29/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0137\n",
      "Epoch 30/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0117\n",
      "Epoch 31/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0107\n",
      "Epoch 32/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0106\n",
      "Epoch 33/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0115\n",
      "Epoch 34/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0118\n",
      "Epoch 35/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0093\n",
      "Epoch 36/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0099\n",
      "Epoch 37/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0110\n",
      "Epoch 38/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0085\n",
      "Epoch 39/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0098\n",
      "Epoch 40/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0090\n",
      "Epoch 41/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0082\n",
      "Epoch 42/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0069\n",
      "Epoch 43/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0094\n",
      "Epoch 44/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0088\n",
      "Epoch 45/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0087\n",
      "Epoch 46/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0049\n",
      "Epoch 47/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0119\n",
      "Epoch 48/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0094\n",
      "Epoch 49/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0073\n",
      "Epoch 50/50\n",
      "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0079\n",
      "✅ Test Accuracy: 0.995\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(y_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=6, verbose=1)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"✅ Test Accuracy: {acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wf-practive-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9dd8f81c8b7834c9610102fe12c8a0a82ea63ba795508c82142f149d0003ca37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
